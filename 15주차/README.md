# 11 / 8 - 12

### 1. 강의 복습

Software 1.0 vs Software 2.0

- Software 1.0은 문제정의, 작은 문제들로 분해, 개별 문제별로 알고리즘 설계, 합쳐 하나의 시스템이라는 순서를 갖는다.
- 이미지 인식을 예로 들면 사람의 개입이 있어 특징을 추출했다.
- 하지만 Software 2.0(딥러닝)은 사람의 개입이 없다는 특징이 있으며 성능향상에 크게 도움이 되었다.
- AI 모델의 구조로 프로그램의 검색범위를 한정시키고, 데이터와 최적화 방법으로 최적의 프로그램을 찾는 방법론이다.

AI 모델의 생애주기

- 일반적으로 수업이나 연구에선 데이터셋이 정해져있고, 더 좋은 모델을 찾는 실험을 많이 하게된다.
- 하지만 서비스 개발시에는 요구사항만 존재한다.
- 서비스향 AI 모델 개발 과정은 요구사항 작성, 데이터셋 준비, 학습 및 디버깅, 설치 및 유지보수의 단계로 나누어진다.
- 요구사항을 충족시키기 위해 데이터나 모델을 변경하기도 한다.
- 서비스 출시 이후 모델을 변경하는 것은 다른 요구사항에 대한 검증도 필요하기 때문에 비용이 크다.(데이터는 그렇지 않다.)
- 데이터에 관련된 논문이 모델에 비해 매우 적기 때문에 인력이 많이 필요하다.
- 또한 라벨링 작업 역시 쉽지 않기 때문에 인력이 많이 필요하다.
- 노이즈가 있는 라벨링을 무시할 정도로 깨끗한 데이터가 2배 이상 필요하다.
- 노이즈는 데이터의 분포도와 연관이 있다.
- 데이터의 불균형을 바로 잡기가 어렵다.
- 완벽한 가이드를 만드는 것이 불가능하다고 인지하고 잘못된 라벨링을 인지하고 수정하는 것이 더 중요하다.
- Software 2.0 IDE에 필요한 기능들은 데이터셋 시각화, 데이터셋 라벨링, 데이터셋 정제, 성능향상을 위한 데이터셋 선별등이 있다.

OCR - Optical Character Recognition
- 글자 영역을 먼저 찾고, 글자를 인식한다.
- Offline과 Online이 있다.
- Detector, Recognizer, Serializer, Parser로 이뤄진다.

글자 영역 검출
- 일반 객체 검출과 다르게 text라는 단일 객체의 위치만 검출하는 문제이며 밀도가 높다.
- 또한 종횡비가 극단적이며 특이한 모양을 가질 수 있다.
- 다각형 모양과 시계방향, 그리고 짝수개의 점을 갖게 라벨링한다.
- Regression-based model은 이미지를 입력받아 글자 영역의 표현값들을 출력해주는데, anchor박스를 활용한다.
- 다만 다각형의 모습과 극단적인 종횡비를 표현하는데 한계가 있다.
- Segmentation-based model은 이미지를 입력받아 글자 영역 표현값들에 사용되는 화소 단위 정보를 뽑아낸 뒤, 후처리를 통해 최종 글자 영역 표현값들을 출력해준다.
- 다만 후처리가 오래 걸릴 수 있고 인접하거나 간섭에 영향을 받는다.
- 이외에도 Hybrid, Character, Word based model 등이 있다.

an Efficient and Accurate Scene Text Detector (EAST)
- Software 2.0 방식으로 개발된 모델로 Unet modelll 형태를 띄고있다.
- 글자 영역 중심에 해당하는 지에 대한 Score map과 Bounding box 위치를 알려주는 Geometric map이 있다.
- 수 많은 bounding box를 합치는 데 locality aware NMS를 사용했고, loss로는 score map(cross-entropy)과 geometric map(IoU와 cosine angle)을 사용했다.

데이터셋
- public dataset은 쉽게 확보할 수 있지만 목적에 맞지 않을 수 있고 수량도 적다.
- created dataset은 합성하여 쉽게 확보할 수 있지만 실제와 다를 수 있고, 실제 데이터는 크롤링해서 빠르게 얻을 수 있지만 다양하고 고화질을 얻기 힘들며 라이선스에 유의해야한다. 직접 모으는 이미지는 비용이 크지만 고품질을 얻을 수 있다.

Annotation Guide
- 좋은 데이터를 확보하기 위한 과정을 정리한 문서다.
- 좋은 데이터는 골고루 모여있으며 일정하게 라벨링된 데이터다.
- 제작 목적에 따라 가이드라인 제작 방법이 달라질 수 있다.
- 크롤링을 통해 데이터를 모을 때 좋은 키워드를 설정해 필터링한다.
- 가이드라인은 수시로 변경되기 때문에 versioning이 중요하다.
- 완벽한 가이드라인은 한번에 완성될 수 없기 때문에 반복작업을 효율적이게 하는 것이 중요하다.

성능 평가 방식
- 학습 데이터와 평가 데이터를 분리하여 사용하는 것은 중요하다.
- 일반적인 성능평가에 Precision, Recall 등의 지표를 사용한다.
- 글자검출에서는 두 영역간의 매칭 판단 방법과 매칭 행렬에서 유사도 계산이 정의되어야 한다.
- IoU, Area Precision, Area Recall은 두 영역간의 매칭 판단 지표중 하나다.
- DetEval이라는 방법은 one-to-one, many-to-one(merge)은 지향하지만, one-to-many(split)는 지양한다.
- IoU 방법은 one-to-one만 허용하는 방법이다.
- TIoU(Tightness-aware IoU)는 부족하거나 초과된 영역에 크기만큼 패널티를 부여하는 방법이다.
- CLEval은 TIoU의 한계를 극복한 방법으로 검출기의 성능은 인식기에 맞추어야 한다는 생각으로 고안되었다.
- CLEval은 얼마나 많은 글자 수를 맞추었는 지에 기반한 방법이다.
- 목적에 맞게 다른 성능 평가 방식을 선택하는 것이 중요하다.

Annotation tools
- LabelMe는 설치가 쉽고 python으로 작성되어 커스터마이징이 가능하지만, 공동작업이 불가능하며 object, image에 속성을 부여할 수 없다.
- CVAT는 web 기반으로 동작하며 다양한 annotation 기능과 자동 annotation, 공동 작업이 가능하지만 inference가 느리고 속성을 부여하기 까다롭다.
- Hasty labeling tool은 다양한 annotation이 가능하고 cloud 지원과 공동 작업이 가능하지만 유료이며 커스터마이징이 불가능하다.


---

### 2. 과제 수행 과정 / 결과물 정리

캠퍼분들이 직접 라벨링한 데이터를 받아 EDA를 진행했다.

노이즈가 많을 것이라 예상하고 먼저 하나하나 확인하였는데, 가이드라인이 지켜지지 않은 것들이 많았다.

이를 하나하나 고치기엔 너무 시간이 많이 걸릴 것 같아 기존 OCR 라이브러리로 cleaning을 해야겠다고 생각했다.

---

### 3. 피어세션 정리

https://github.com/boostcampaitech2/data-annotation-cv-level3-cv-14/discussions


---

### 4. 학습 회고

자유 프로젝트 주제에 관해 계속해서 고민했다.

GAN 관련 주제를 하게될 것 같은데, GAN에 관해 복습하며 다른 모델들도 찾아가며 공부해야겠다.