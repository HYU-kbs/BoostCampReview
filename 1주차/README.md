# 8 / 2 (월)

### 1. 강의 복습 

PreCourse에서 배운 내용이 대부분이어서 중요하거나 헷갈리다고 생각되는 부분을 복습했다.

* 파이썬 기본 자료구조
    - **Stack**
        - Last In First Out
        - 리스트의 append()와 pop()으로 구현 가능
    - **Queue**
        - First In First Out
        - 리스트의 append()와 pop(0)로 구현 가능
    - **Tuple**
        - 값의 변경이 불가능한 리스트
        - 실수로 인해 값이 변경되는 것을 방지
    - **Set**
        - 순서없이 값을 중복되지 않게 저장하는 자료구조
        - add(), remove(), 수학에서의 집합연산을 지원
    - **Dict**
        - Key 값을 활용하여 Value 값을 저장
    - **Deque**
        - Stack과 Queue를 지원하는 모듈
        - rotate나 reverse같은 linked list의 특성을 갖음
    - **Counter**
        - element의 갯수를 세어 dict 형태로 반환
        - Set 연산을 지원
    
* Pythonic code
    - **Generator**
        - iterable object를 특수한 형태로 사용해주는 함수
        - yield 키워드를 사용하거나 ()를 이용한 generator comprehension을 사용
        - 값이 사용될때만 호출이 되어 큰 데이터를 처리할 때 메모리 공간을 효율적으로 사용
    - **가변인자 (Variable-length)**
        - parameter로 *args 변수명을 사용
        - tuple로 인식  
        - ```python
          def summation(*args):
              return sum(args)
          ```
    - **키워드 가변인자 (Keyword variable-length)**
        - parameter로 **kwargs 변수명을 사용
        - dict로 인식
        - ```python
          def kwargs_test(one, two=3, *args, **kwargs):
              pass
          
          kwargs_test(10, 300, first=3, second=2, third=5)
          ```
    
* 벡터와 행렬
    - **벡터**
        - 공간에서의 한 점을 나타낸다
        - 원점으로부터 상대적 위치를 나타낸다
    - **벡터의 노름**
        - 원점에서부터의 거리를 나타내는 값
        - L1-노름은 각 성분의 변화량의 절대값을 더한 값
        - L2-노름은 유클리드 거리 값
    - **행렬**
        - 벡터를 원소로 가지는 2차원 배열
        - 공간에서의 여러 점을 나타낸다
        - 벡터 공간에서 사용되는 연산자로 이해할 수 있다 (벡터를 다른 차원으로 보낼 수 있다)
    - **역행렬**
        - 행렬의 연산을 되돌리는 행렬
        - 행과 열이 같고 determinant가 0이 아니어야 계산 가능하다
        - 역행렬을 계산할 수 없을 때 유사 역행렬인 **무어-펜로즈 역행렬**을 이용한다
   
* 경사하강법
    - **변수가 1개일 때**
        - 한 점에서의 미분값을 빼면서 함수의 극소값을 구할 수 있다
    - **변수가 여러개 일 때 (벡터)**
        - 편미분을 이용하여 gradient vector를 구한다
        - 한 점에서의 미분값을 빼면서 함수의 극소값을 구할 수 있다
    - **경사하강법을 이용한 선형회귀 분석**
        - 여러 점들을 행렬 X로 표현, coefficient vector를 b, 정답이 되는 벡터를 y라고 할때,
        - 선형회귀의 목적식은 y-Xb의 L2-노름이다
        - 목적식을 최소화하는 과정에서 b에 대해 편미분이 이용된다
        - 비선형회귀에서는 경사하강법 수렴이 보장되지 않는다
    
* 확률적 경사하강법
    - 모든 데이터가 아닌 일부만을 사용하여 업데이트한다
    - 연산량이 줄어드는 효과가 있다
    - 목적식이 계속해서 변화하므로 non-convex 계산식에도 적용가능하다
    
---
### 2. 과제 수행 과정 / 결과물 정리
처음으로 수행한 필수과제는 별로 어렵지 않았다

정규표현식 regex를 이용하면 더욱 깔끔한 코딩을 할 수 있을 것 같다

* Assignment1_Basic_Math
    - numpy를 import하여 각각 np.max, np.min, np.mean, np.median을 이용하였다
    
* Assignment2_Text_Processing_1
    - normalize 함수를 구현할 때 split()과 join()을 이용하였다
    - no_vowel_string 함수를 구현할 때 for loop를 이용하여 모음이 아닐 때만 return값에 더해주었다
    
* Assignment3_Text_Processing_II
    - digits_to_words 함수를 구현할 때, 숫자에 대응하는 영어 단어를 저장하는 list를 만들었다

---
### 3. 피어세션 정리

처음 한 피어세션에서 여러 캠퍼들을 만날 수 있었고, 앞으로 피어세션을 어떻게 진행할지 정하였다

모더레이터는 매일 돌아가며 맡기로 하였고, 피어세션을 진행하기로 하였다

피어세션에서 서로 강의중에 생긴 질문을 물어보며 답하는 시간과 코드 리뷰와 피드백을 진행하기로 하였다

---
### 4. 학습 회고

첫 날부터 많은일이 진행된것 같아 정신없었지만, 앞으로 많은 캠퍼들과 협업하여 프로젝트를 진행해보고 싶다

당장은 알고있는 내용 위주로 공부하고 있지만, 잘 정리해서 온전히 내 것으로 만들어야겠다고 생각했다


# 8 / 3 (화)

### 1. 강의 복습 

* Object Oriented Programming
    - OOP는 설계도인 class와 구현체인 instance로 나눌 수 있다.
    - 파이썬에서 class는 다음과 같이 정의한다
        ```python
      class SoccerPlayer():
            def __init__(self, name, position, back_number):
                self.name = name
                self.position = position
                self.back_number = back_number
        ```
    - OOP의 특성
        - **상속 (Inheritance)** - 부모 클래스로부터 속성과 method를 물려받는다.
        - **다형성 (Polymorphism)** - 같은 이름의 method를 다르게 작성할 수 있다.
        - **가시성 (Visibility)** - 객체의 정보를 볼 수 있는 레벨을 조정하는 것이다.
    
* Decorator
    - 함수의 parameter로 다른 함수를 쓸 수 있다.
    - 함수 내에서 다른 함수를 정의할 수 있다.
    - 함수 내에서 다른 함수를 반환하는 것을 클로저(closure)라고 하고, 이를 간단하게 사용하게 하려면 decorator를 이용한다.
    
* Module and Project
    - Module은 .py 파일이며 import문을 사용하여 호출한다.
    - 모듈의 특정 함수만 불러오려면 from ... import ... 와 같이 사용하거나 as로 별칭을 이용한다.
    - Package는 다양한 모듈의 모음이다.
    - 패키지를 구성할 때에는 \_\_init__.py를 만들고, 하위폴더와 py파일을 포함한다. 또, \_\_all__키워드를 사용한다.
    
* 딥러닝 학습방법
    - 분류 문제에선 모델의 출력을 확률로 변환하는 함수인 softmax함수가 이용된다.
    - 비선형 모델을 학습시키려면 활성화 함수가 필요하다. (sigmoid, tanh, ReLU)
    - 층을 여러개 쌓게되면 목적함수를 근사하는데 더 적은 뉴런만 학습시키면 된다.
    - chain-rule을 기반으로 back propagation이 이루어진다.
    
* 딥러닝과 확률론
    - 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두고 있다.
    - 목적식인 loss function들의 작동원리는 데이터 공간의 통계학적 해석으로 유도된다.
    - L2-norm은 예측오차의 분산을 최소화하는 방향으로 학습된다.
    - cross-entropy는 모델 예측의 불확실성을 최소화하는 방향으로 학습된다.
    - 확률분포를 알면 데이터를 알 수 있다.
    - 데이터가 주어지더라도 확률분포를 알 수 없기때문에 **몬테카를로 샘플링** 방법을 이용하여 기대값을 구한다.

---

### 2. 과제 수행 과정 / 결과물 정리

정규표현식 regex를 사용한다면 쉽게 text 전처리가 가능할 것 같았다.

하지만 regex가 익숙하지 않아 익숙한 방법으로 코딩을 진행해나갔다.

과제가 각각의 함수들로 잘 구분되어있어서 수행해나가는데 큰 어려움은 없었다.

* Assignment4_Baseball
    - 전체적으로 어렵진 않았지만 프로그램의 입출력 설명이 애매해 잘못 이해해서 많이 헤맸던 것 같다.

* Assignment5_Morsecode
    - dict를 이용하여 알파벳을 모스부호로 쉽게 바꿀 수 있었다.
    - 하지만 모스부호를 알파벳으로 바꿀 때에는 key와 value가 뒤바뀐 dict가 필요하여 dict comprehension을 이용하였다.
    - join과 split을 이용하여 문자열을 다루었다.

---

### 3. 피어세션 정리 
* 강의중에 배운 무어-펜로즈 역행렬의 이해방법과 유도방법을 이야기하였다.
    - 무어-펜로즈 역행렬은 SVD를 활용하여 유도할 수 있다.
    
* 강의중에 배운 경사 하강법 목적식에 대해 이야기하였다.
    
* 미니배치를 활용하여 학습할 때, 왜 연산량이 줄어들지에 대해 고민해보았다.
    - 빠른 GPU의 연산을 활용하여 시간을 줄인다고 생각했다.
    
* 멘토님과 5일 20시에 모임을 갖기로 하였다.

* 오늘 한 과제에 대해 막히는 부분에 대해 서로 질문했다.
    - 단순히 과제가 어렵기보단, 나처럼 입출력 설명을 잘못 이해했다.
    
* 매주 금요일에 AI 관련 기술, 이론, 논문 등을 발표하기로 하였다.
    - 앞으로 학습 난이도가 증가해서 시간이 부족해질 수도 있다.


---

### 4. 학습 회고

precourse에서 이해되지않았던 확률론 부분을 다시 들어보니 전보다 훨씬 이해되는 것 같았다.

과제 자체는 어렵지 않았지만 많이 헤매었던 것이 아쉬웠다.

피어세션에서 나도 모르고 지나갈 뻔한 질문들을 함께 고민하는 과정이 정말 좋았다.